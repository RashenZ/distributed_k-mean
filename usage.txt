
At the beginning we wanted to do a DKM (Distributed K-Means) with real data that came from different meteo API (). We this method we would've been able to create cluster depending of the information we retrieved. For this we wanted to use those following library:
- networkx : Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks.
- pandas : open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language
- sklearn : Open-source ML (Machine Learning) library for Python. sklearn (Scikit-learn) is a library in Python that provides many unsupervised and supervised learning algorithms.

But we realize after one week that we were still stuck on the usage of networkx and sklearn so we decided to give this idea up because of time. [NEED BULLSHIT FOR THIS PART AYAAAAAA]

At the end we created a script that generate raw data.

HOW OUR PROGRAM WORK ?
Usage of our script called DataGenerator.py :

[DAVID WILL WRITE ]

After creating our file if all the data

[PARSING DAVID WILL WRITE OR ME AFTER]

We initialize our class DistributedKMeans by sending in parameters :
- self.Xm = Xm # Set of all observation of not m {nodex: [observation1, observation2]}
		- Xm 	= Set of all observation of not m {nodex: [observation1, observation2, ..., observation(n)]}
		- M 	= Number of node
		- K 	= Number of cluster
		- Nm  	= Number of observation of node m
If you don't send one of those paramaeters, a default value will be set:
		- Xm 	= {"0": [1, 2, 3, 15], "1": [2, 2, 5, 1], "2": [4, 3, 10, 50]}
		- M 	= 5
		- K 	= 3
		- Nm 	= 10

Once everything is setup we call a method function called "start"
 $> KMeans.start()

 this function will set our cluster (depending on the data we have) by calling the method self.distributedVarPart().
 Through this function we'll 
 first : initialize our cluster
 then we'll set a centroid for each cluster
 and after calculate the SSE (Sum of Squares Error) also for each of them ( function calculateSSE(self, cluster, center) ) and depending of the result :
 	. If the SSE is too big the cluster will be split it in 2 sub-cluster (function splitCluster(self, cluster) ).
 	. Else we keep the cluster like this.

Now that we initialized our cluster and our centroid we can start our loop that will iterate and calculate the new centroid for each cluster.
After calculating the new centroid the program will display them as followed:

$> turn t=0: Centroids[10, 23, 14, 2, ..., x]
$> turn t=1: Centroids[10, 24, 13, 2, ..., x]
$> turn t=N: Centroids[a, b, c, d, ..., x]